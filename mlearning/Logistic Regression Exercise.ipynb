{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "In this exercise, you will build a logistic regression model to predict whether a student gets admitted into a university. Suppose that you are the administrator of a university department and you want to determine each applicant's chance of admission based on their results on two exams. You have historical data from previous applicants that you can use as a training set for logistic regression. For each training example, you have the applicant's scores on two exams and the admissions decision.\n",
    "\n",
    "Your task is to **build a classification model** that estimates an applicant's probability of admission based the scores from those two exams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Function\n",
    "\n",
    "Before you start with the actual cost function, recall that the logistic regression hypothesis is defined as:\n",
    "\n",
    "$$h_\\theta(x) = g(\\theta^Tx)$$\n",
    "\n",
    "where function $g$ is the sigmoid function. The sigmoid function is defined as:\n",
    "\n",
    "$$g(z) = \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "The cost function as a logistic regression hypothesis is defined as:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} [ -y^{(i)}\\ log (h_{\\theta}(x^{(i)})) - (1 - y^{(i)})\\ log(1 - h_{\\theta}(x^{(i)})) ]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The gradient of the cost is a vector of the same length as $\\theta$ where the $j$th element (for $j=0, 1,..., n$) is defined as follows:\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i-1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to optimize the iteration between Gradient Descent and Cost Function to find the best value of $\\theta$, you may use the SciPy function `opt` from `scipy.optimize` as described below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "result = opt.fmin_tnc(func=cost_function, x0=theta, fprime=gradient_descent, args=(X, y))\n",
    "cost_function(result[0], X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `cost_function` is your implementation of the cost function, `gradient_descent` is your implementation of the gradient descent function, `theta` is your initial theta value (for this problem, you may initialize $\\theta$ as with zeros). Finally, `args` receives your (100, 3) and (100, 1) matrices corresponding to the training set and true labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIPS\n",
    "\n",
    "- In order to improve computational cost, add 1 values to the X matrix as:\n",
    "\n",
    "```\n",
    "[[1, v1, v2],\n",
    " [1, v3, v4],\n",
    " [1, v5, v6],\n",
    " ...\n",
    "]\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEPS\n",
    "\n",
    "- Load the content of the file data.txt\n",
    "- Plot the values separated by each class to check the distribution of the values\n",
    "- Implement the Sigmoid function\n",
    "- Test the Sigmoid function using values from -10 to 10 and check if it reaches the point (0, 0.5).\n",
    "- Implement the Cost Function\n",
    "- Test the Cost Function using $\\theta=[0., 0., 0]$ :: $J(\\theta)$ should give 0.6931\n",
    "- Implement Gradient Descent \n",
    "- Test Gradient Descent : Gradient should return [-0.1, -12.00921659, -11.26284221]\n",
    "- Apply the SciPy optimization function : this function should return the values of $\\theta$ = [-25.16131859, 0.20623159, 0.20147149]\n",
    "- Test all occurrences of X with this new value of theta and check the number of correct predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
