{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet\n",
    "\n",
    "Implementation of LeNet by LeCun et al. [1] in Keras. LeNet has the following structure:\n",
    "\n",
    "<img src=\"images/lenet.png\" width=\"80%\"/>\n",
    "\n",
    "<img src=\"images/lenet_test.gif\"/>\n",
    "\n",
    "A testing of the network by Yann LeCun in 1993 can be watched in [YouTube](https://www.youtube.com/watch?v=FwFduRA_L6Q)\n",
    "\n",
    "The data used in this example can be found in [Kaggle]( https://www.kaggle.com/c/digit-recognizer/data) site.\n",
    "\n",
    "[1] Y. Lecun, L. Bottou, Y. Bengio and P. Haffner, \"Gradient-based learning applied to document recognition,\" in Proceedings of the IEEE, vol. 86, no. 11, pp. 2278-2324, Nov. 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc6a4f5cc88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "Y_train = train[['label']]\n",
    "X_train = train.drop(train.columns[[0]], axis=1)\n",
    "X_test = test\n",
    "\n",
    "#Visualizing the data\n",
    "sample = X_train.iloc[10, :]\n",
    "sample = sample.values.reshape([28,28])\n",
    "plt.imshow(sample, cmap='gray')\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)\n",
    "\n",
    "#Reshape the training and test set\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "#Padding the images by 2 pixels since in the paper input images were 32x32\n",
    "X_train = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "X_test = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
    "\n",
    "#Standardization\n",
    "mean_px = X_train.mean().astype(np.float32)\n",
    "std_px = X_train.std().astype(np.float32)\n",
    "X_train = (X_train - mean_px)/(std_px)\n",
    "\n",
    "#One-hot encoding the labels\n",
    "Y_train = to_categorical(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "#Conv Layer 1\n",
    "model.add(Conv2D(filters=6, \n",
    "                 kernel_size=5, \n",
    "                 strides=1, \n",
    "                 activation='relu', \n",
    "                 input_shape=(32,32,1)))\n",
    "#Pooling layer 1\n",
    "model.add(MaxPooling2D(pool_size=2, \n",
    "                       strides=2))\n",
    "#Conv Layer 2\n",
    "model.add(Conv2D(filters=16, \n",
    "                 kernel_size=5, \n",
    "                 strides=1, \n",
    "                 activation='relu', \n",
    "                 input_shape=(14,14,6)))\n",
    "#Pooling Layer 2\n",
    "model.add(MaxPooling2D(pool_size=2, \n",
    "                       strides=2))\n",
    "#Flatten\n",
    "model.add(Flatten())\n",
    "#Fully connected layer 1\n",
    "model.add(Dense(units=120, \n",
    "                activation='relu'))\n",
    "#Fully connected layer 2\n",
    "model.add(Dense(units=84, \n",
    "                activation='relu'))\n",
    "#Output Layer\n",
    "model.add(Dense(units=10, \n",
    "                activation='softmax'))\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/42\n",
      "10/10 [==============================] - 16s 2s/step - loss: 1.9122 - acc: 0.4581\n",
      "Epoch 2/42\n",
      "10/10 [==============================] - 4s 438ms/step - loss: 0.8769 - acc: 0.7849\n",
      "Epoch 3/42\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.3902 - acc: 0.8835\n",
      "Epoch 4/42\n",
      "10/10 [==============================] - 4s 436ms/step - loss: 0.2737 - acc: 0.9177\n",
      "Epoch 5/42\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 0.2127 - acc: 0.9362\n",
      "Epoch 6/42\n",
      "10/10 [==============================] - 4s 434ms/step - loss: 0.1702 - acc: 0.9499\n",
      "Epoch 7/42\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.1398 - acc: 0.9592\n",
      "Epoch 8/42\n",
      "10/10 [==============================] - 4s 417ms/step - loss: 0.1172 - acc: 0.9653\n",
      "Epoch 9/42\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.1002 - acc: 0.9706\n",
      "Epoch 10/42\n",
      "10/10 [==============================] - 4s 437ms/step - loss: 0.0871 - acc: 0.9741\n",
      "Epoch 11/42\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 0.0769 - acc: 0.9770\n",
      "Epoch 12/42\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.0687 - acc: 0.9798\n",
      "Epoch 13/42\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.0619 - acc: 0.9820\n",
      "Epoch 14/42\n",
      "10/10 [==============================] - 4s 415ms/step - loss: 0.0561 - acc: 0.9837\n",
      "Epoch 15/42\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.0511 - acc: 0.9851\n",
      "Epoch 16/42\n",
      "10/10 [==============================] - 4s 426ms/step - loss: 0.0468 - acc: 0.9863\n",
      "Epoch 17/42\n",
      "10/10 [==============================] - 4s 422ms/step - loss: 0.0429 - acc: 0.9878\n",
      "Epoch 18/42\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.0395 - acc: 0.9889\n",
      "Epoch 19/42\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.0366 - acc: 0.9896\n",
      "Epoch 20/42\n",
      "10/10 [==============================] - 4s 423ms/step - loss: 0.0339 - acc: 0.9905\n",
      "Epoch 21/42\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.0314 - acc: 0.9912\n",
      "Epoch 22/42\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.0291 - acc: 0.9919\n",
      "Epoch 23/42\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.0272 - acc: 0.9925\n",
      "Epoch 24/42\n",
      "10/10 [==============================] - 4s 429ms/step - loss: 0.0253 - acc: 0.9933\n",
      "Epoch 25/42\n",
      "10/10 [==============================] - 4s 414ms/step - loss: 0.0239 - acc: 0.9938\n",
      "Epoch 26/42\n",
      "10/10 [==============================] - 4s 430ms/step - loss: 0.0222 - acc: 0.9943\n",
      "Epoch 27/42\n",
      "10/10 [==============================] - 4s 407ms/step - loss: 0.0206 - acc: 0.9949\n",
      "Epoch 28/42\n",
      "10/10 [==============================] - 4s 418ms/step - loss: 0.0192 - acc: 0.9953\n",
      "Epoch 29/42\n",
      "10/10 [==============================] - 4s 412ms/step - loss: 0.0179 - acc: 0.9957\n",
      "Epoch 30/42\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.0167 - acc: 0.9960\n",
      "Epoch 31/42\n",
      "10/10 [==============================] - 4s 410ms/step - loss: 0.0160 - acc: 0.9962\n",
      "Epoch 32/42\n",
      "10/10 [==============================] - 4s 432ms/step - loss: 0.0147 - acc: 0.9966\n",
      "Epoch 33/42\n",
      "10/10 [==============================] - 4s 419ms/step - loss: 0.0136 - acc: 0.9971\n",
      "Epoch 34/42\n",
      "10/10 [==============================] - 4s 416ms/step - loss: 0.0125 - acc: 0.9974\n",
      "Epoch 35/42\n",
      "10/10 [==============================] - 4s 441ms/step - loss: 0.0116 - acc: 0.9977\n",
      "Epoch 36/42\n",
      "10/10 [==============================] - 4s 425ms/step - loss: 0.0108 - acc: 0.9980\n",
      "Epoch 37/42\n",
      "10/10 [==============================] - 4s 427ms/step - loss: 0.0100 - acc: 0.9983\n",
      "Epoch 38/42\n",
      "10/10 [==============================] - 4s 413ms/step - loss: 0.0093 - acc: 0.9984\n",
      "Epoch 39/42\n",
      "10/10 [==============================] - 4s 435ms/step - loss: 0.0086 - acc: 0.9987\n",
      "Epoch 40/42\n",
      "10/10 [==============================] - 4s 420ms/step - loss: 0.0080 - acc: 0.9989\n",
      "Epoch 41/42\n",
      "10/10 [==============================] - 4s 421ms/step - loss: 0.0075 - acc: 0.9990\n",
      "Epoch 42/42\n",
      "10/10 [==============================] - 4s 411ms/step - loss: 0.0070 - acc: 0.9992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc668a82438>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train model\n",
    "model.fit(X_train ,Y_train, steps_per_epoch = 10, epochs = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Converting one hot vectors to labels\n",
    "labels = np.argmax(y_pred, axis=1)\n",
    "index = np.arange(1, 28001)\n",
    "labels = labels.reshape([len(labels), 1])\n",
    "index = index.reshape([len(index), 1])\n",
    "final = np.concatenate([index, labels], axis=1)\n",
    "\n",
    "#Prediction csv file\n",
    "np.savetxt(\"results_mnist.csv\", final, delimiter = \" \", fmt = '%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
