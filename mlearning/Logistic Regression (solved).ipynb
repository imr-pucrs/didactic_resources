{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load content\n",
    "X, y = [], []\n",
    "with open('/home/roger/Desktop/rmi/data.txt') as fin:\n",
    "    for line in fin:\n",
    "        arr = line.strip().split(',')\n",
    "        v1 = float(arr[0])\n",
    "        v2 = float(arr[1])\n",
    "        v = int(arr[2])\n",
    "        X.append([v1, v2])\n",
    "        y.append(v)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y = y.reshape((-1, 1)) \n",
    "print X.shape\n",
    "print y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get positive and negative vectors\n",
    "approved = []\n",
    "rejected = []\n",
    "for arr, lbl in zip(X, y):\n",
    "    x1, x2 = arr\n",
    "    if lbl == 1:\n",
    "        approved.append(arr)\n",
    "    else:\n",
    "        rejected.append(arr)\n",
    "approved = np.array(approved)\n",
    "rejected = np.array(rejected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show how data is distributed\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.plot(approved[:,0], approved[:,1], 'rx', label='approved')\n",
    "plt.plot(rejected[:,0], rejected[:,1], 'bo', label='rejected')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Exam 1 score')\n",
    "plt.ylabel('Exam 2 score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the Sigmoid function\n",
    "\n",
    "The sigmoid function is defined as:\n",
    "\n",
    "$$g(z) = \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Implement the Sigmoid function\n",
    "def sigmoid_for(z):\n",
    "    \"\"\" Sigmoid function using for \"\"\"\n",
    "    g = np.zeros(z.shape)\n",
    "    w, h = z.shape\n",
    "    for i in range(0, w):\n",
    "        for j in range(0, h):\n",
    "            g[i, j] = 1./(1 + np.exp(-z[i,j]))\n",
    "    return g\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\" Sigmoid function \"\"\"\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the Sigmoid function\n",
    "\n",
    "range_vals = np.arange(-10, 10, step=1)\n",
    "zero_vals = np.array(20*[0.5])\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "ax.plot(range_vals, sigmoid(range_vals), 'r')\n",
    "ax.plot(range_vals, zero_vals, '#0F0F0F')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function\n",
    "\n",
    "The cost function as a logistic regression hypothesis is defined as:\n",
    "\n",
    "$$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^{m} [ -y^{(i)}\\ log (h_{\\theta}(x^{(i)})) - (1 - y^{(i)})\\ log(1 - h_{\\theta}(x^{(i)})) ]$$\n",
    "\n",
    "where \n",
    "$$h_{\\theta}(x^{(i)}) = \\sigma(X\\theta^T) = g(X\\theta^T)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation of the Cost Function\n",
    "def cost_function(theta, X, y):\n",
    "    \"\"\" Compute the cost function of theta \"\"\"\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    first = np.multiply(-y, np.log(sigmoid(X * theta.T)))\n",
    "    second = np.multiply((1 - y), np.log(1 - sigmoid(X * theta.T)))\n",
    "    J = np.sum(first - second) / (len(X))\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add column to X since it makes computation easier\n",
    "m, n = X.shape\n",
    "X = np.c_[np.ones(m), X]\n",
    "theta = np.zeros(n+1)\n",
    "J = cost_function(theta, X, y)\n",
    "print J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "\n",
    "The gradient of the cost is a vector of the same length as $\\theta$ where the $j$th element (for $j=0, 1,..., n$) is defined as follows:\n",
    "\n",
    "$$\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = \\frac{1}{m} \\sum_{i-1}^{m} (h_{\\theta}(x^{(i)}) - y^{(i)})x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(theta, X, y):\n",
    "    theta = np.matrix(theta)\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    \n",
    "    parameters = int(theta.ravel().shape[1])\n",
    "    grad = np.zeros(parameters)\n",
    "    \n",
    "    error = sigmoid(X * theta.T) - y\n",
    "    \n",
    "    for i in range(parameters):\n",
    "        term = np.multiply(error, X[:,i])\n",
    "        grad[i] = np.sum(term) / len(X)\n",
    "    \n",
    "    return grad\n",
    "\n",
    "print gradient(theta, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.optimize as opt\n",
    "result = opt.fmin_tnc(func=cost_function, x0=theta, fprime=gradient_descent, args=(X, y))\n",
    "cost_function(result[0], X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(theta, X):\n",
    "    probability = sigmoid(X * theta.T)\n",
    "    return [1 if x >= 0.5 else 0 for x in probability]\n",
    "\n",
    "theta_min = np.matrix(result[0])\n",
    "predictions = predict(theta_min, X)\n",
    "scores = []\n",
    "for a, b in zip(predictions, y):\n",
    "    if (a and b) or (not a and not b):\n",
    "        scores.append(1)\n",
    "    else:\n",
    "        scores.append(0)\n",
    "accuracy = (sum(map(int, scores)) % len(scores))\n",
    "print 'accuracy = {0}%'.format(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
